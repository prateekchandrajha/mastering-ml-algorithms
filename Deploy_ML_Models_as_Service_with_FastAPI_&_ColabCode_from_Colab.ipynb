{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deploy ML Models as Service with FastAPI & ColabCode from Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prateekchandrajha/mastering-ml-algorithms/blob/main/Deploy_ML_Models_as_Service_with_FastAPI_%26_ColabCode_from_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfkUNsC_T2qy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b820474-5fb1-4b92-b872-42a7406fe2de"
      },
      "source": [
        "!pip install colabcode\n",
        "!pip install fastapi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colabcode\n",
            "  Downloading https://files.pythonhosted.org/packages/83/12/036633665b7aa8bc444a23c4922b8841f8628128d671f111046f3f7d2a55/colabcode-0.1.2-py3-none-any.whl\n",
            "Collecting uvicorn==0.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hCollecting pyngrok>=5.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/19/af0fc6c11cc13f8a31e9dbec21af745337be8a40b5738cd30f08a483eac3/pyngrok-5.0.1.tar.gz\n",
            "Collecting nest-asyncio==1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/33/10805a3359f56ac4f3b520e64b9d5e6a288d87be95777b8023c64cba60f1/nest_asyncio-1.4.3-py3-none-any.whl\n",
            "Collecting h11>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/0f/7a0eeea938eaf61074f29fed9717f2010e8d0e0905d36b38d3275a1e4622/h11-0.12.0-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.13.1->colabcode) (3.7.4.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyngrok>=5.0.0->colabcode) (3.13)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-5.0.1-cp36-none-any.whl size=18822 sha256=3ce53532eb2c65342d9067a379c7b3f085e0ef22011cfe890e5417befeb08429\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/01/05/d39efb8f6b40a411354b4168ca9dda99e6f8d586e458e97551\n",
            "Successfully built pyngrok\n",
            "\u001b[31mERROR: nbclient 0.5.1 has requirement jupyter-client>=6.1.5, but you'll have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: h11, uvicorn, pyngrok, nest-asyncio, colabcode\n",
            "  Found existing installation: nest-asyncio 1.5.1\n",
            "    Uninstalling nest-asyncio-1.5.1:\n",
            "      Successfully uninstalled nest-asyncio-1.5.1\n",
            "Successfully installed colabcode-0.1.2 h11-0.12.0 nest-asyncio-1.4.3 pyngrok-5.0.1 uvicorn-0.13.1\n",
            "Collecting fastapi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/33/1b643f650688ad368983bbaf3b0658438038ea84d775dd37393d826c3833/fastapi-0.63.0-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hCollecting starlette==0.13.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/a4/c9e228d7d47044ce4c83ba002f28ff479e542455f0499198a3f77c94f564/starlette-0.13.6-py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.4MB/s \n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/ea/fae9f69b6e56407961318e8c73e203097a97c7bd71b30bf1b4f5eb448f28/pydantic-1.7.3-cp36-cp36m-manylinux2014_x86_64.whl (9.2MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic<2.0.0,>=1.0.0->fastapi) (0.8)\n",
            "Installing collected packages: starlette, pydantic, fastapi\n",
            "Successfully installed fastapi-0.63.0 pydantic-1.7.3 starlette-0.13.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjR3OXrZUWbN"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "from fastapi import FastAPI"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00z03aC9YVGk"
      },
      "source": [
        "cc = ColabCode(port=12000, code=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFXBGHaNUk3h"
      },
      "source": [
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\") # no end point, just the root, a very light-weight app\n",
        "async def read_root():\n",
        "  return {\"message\": \"Subscribe to @1littlecoder\"}"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzWXXJs-UmFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90e3a23-86c2-4629-b873-8fac1fa3fbc5"
      },
      "source": [
        "cc.run_app(app=app)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [62]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"http://8605de063257.ngrok.io\" -> \"http://localhost:12000\"\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"GET / HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [62]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE3gaKk7UpEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d8a888-3ad0-4b5a-9d0f-90a8b9330308"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "iris = load_iris()\n",
        "model = GaussianNB()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1)\n",
        "model_f = model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model score: \", model.score(X_train, y_train))\n",
        "print(\"Test Accuracy: \", model.score(X_test, y_test))\n",
        "\n",
        "pickle.dump(model_f, open(\"model_gb.pkl\", \"wb\"))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model score:  0.9555555555555556\n",
            "Test Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sWUbNKGW9ZX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e613a9-24df-48e5-d9a5-fc3f094b2a86"
      },
      "source": [
        "%%writefile models.py\n",
        "from pydantic import BaseModel, conlist\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class Iris(BaseModel):\n",
        "    data: List[conlist(float, min_items=4, max_items=4)]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing models.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMpFW8OAV2r3"
      },
      "source": [
        "import pickle\n",
        "import logging\n",
        "from fastapi import FastAPI\n",
        "from models import Iris\n",
        "\n",
        "app = FastAPI(title=\"ML Models as API on Google Colab\", description=\"with FastAPI and ColabCode\", version=\"1.0\")\n",
        "\n",
        "# # Initialize logging\n",
        "# my_logger = logging.getLogger()\n",
        "# my_logger.setLevel(logging.DEBUG)\n",
        "# logging.basicConfig(level=logging.DEBUG, filename='logs.log')\n",
        "\n",
        "model = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model\n",
        "    model = pickle.load(open(\"model_gb.pkl\", \"rb\"))\n",
        "\n",
        "@app.post(\"/api\", tags=[\"prediction\"])\n",
        "async def get_predictions(iris: Iris):\n",
        "    try:\n",
        "        data = dict(iris)['data']\n",
        "        print(data)\n",
        "        iris_types = {\n",
        "            0: 'setosa',\n",
        "            1: 'versicolor',\n",
        "            2: 'virginica'\n",
        "        }\n",
        "        prediction = list(map(lambda x: iris_types[x], model.predict(data).tolist()))\n",
        "        log_proba = model.predict_log_proba(data).tolist()\n",
        "        return {\"prediction\": prediction, \"log_proba\": log_proba}\n",
        "    except:\n",
        "        my_logger.error(\"Something went wrong!\")\n",
        "        return {\"prediction\": \"error\"}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFl9Ga5uW5ED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966261f3-481b-4709-ed26-bd2a58dfe0b3"
      },
      "source": [
        "cc.run_app(app=app)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"http://b6c41d4878a9.ngrok.io\" -> \"http://localhost:12000\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [62]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"GET / HTTP/1.1\" 404 Not Found\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"GET /docs HTTP/1.1\" 200 OK\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"POST /api HTTP/1.1\" 422 Unprocessable Entity\n",
            "[[4.5, 3.1, 1.0, 5.0]]\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"POST /api HTTP/1.1\" 200 OK\n",
            "[[0.5, 3.1, 1.0, 5.0]]\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"POST /api HTTP/1.1\" 200 OK\n",
            "[[0.5, 3.1, 199.0, 5.0]]\n",
            "INFO:     2402:e280:2200:5992:45e3:513c:4120:f28:0 - \"POST /api HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vnVzMeKXe5U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}